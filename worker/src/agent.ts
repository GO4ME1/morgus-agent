/**
 * Agent orchestrator for autonomous task execution
 */

import { ToolRegistry } from './tools';
import { callGemini } from './gemini';
import { skillsManager } from './skills';
import { executionLogger } from './skills/execution-logger';
import { taskTracker, requiresTaskPlan, generateTaskPlan } from './skills/task-tracker';
import { formatToolResult, formatErrorForContext, deterministicStringify } from './context';
import { factChecker } from './fact-checker';
import { MORGUS_KERNEL } from './morgus-kernel';

export interface AgentConfig {
  maxIterations?: number;
  temperature?: number;
  model?: string;
}

export interface AgentMessage {
  type: 'status' | 'thought' | 'tool_call' | 'tool_result' | 'response' | 'error' | 'complete';
  content: string;
  metadata?: any;
}

/**
 * Autonomous agent that can use tools and reason through tasks
 */
export class AutonomousAgent {
  private toolRegistry: ToolRegistry;
  private config: AgentConfig;
  private conversationHistory: any[] = [];

  constructor(config: AgentConfig = {}) {
    this.toolRegistry = new ToolRegistry();
    this.config = {
      maxIterations: config.maxIterations || 10, // Allow full task completion
      temperature: config.temperature || 0.7,
      model: config.model || 'gpt-4o-mini', // Switched from gpt-4-turbo-preview to save 95% on costs
    };
  }

  /**
   * Detect if a query likely needs tool use
   */
  private detectToolNeed(message: string): boolean {
    const toolKeywords = [
      'search', 'find', 'look up', 'image', 'picture', 'photo',
      'calculate', 'compute', 'solve', 'what is', 'how many',
      'show me', 'get me', 'fetch', 'retrieve',
      // Website/app building keywords
      'build', 'create', 'make', 'deploy', 'website', 'app', 'page',
      'landing page', 'web', 'html', 'css', 'javascript',
      // Code execution keywords
      'execute', 'run', 'code', 'script', 'program',
      // GitHub keywords
      'github', 'repo', 'repository', 'clone', 'push', 'commit', 'pull request'
    ];
    
    const messageLower = message.toLowerCase();
    return toolKeywords.some(keyword => messageLower.includes(keyword));
  }

  /**
   * Execute a task with streaming updates
   */
  async *executeTask(
    userMessage: string,
    env: any,
    conversationHistory: Array<{role: string, content: string}> = []
  ): AsyncGenerator<AgentMessage> {
    yield {
      type: 'status',
      content: 'ü§ñ Starting task execution...',
    };

    // Start execution logging for self-improving loop
    executionLogger.startExecution(userMessage);

    // Check if task requires planning (todo.md pattern)
    if (requiresTaskPlan(userMessage)) {
      const plan = await generateTaskPlan(userMessage, env.OPENAI_API_KEY);
      if (plan) {
        taskTracker.createPlan(plan.goal, plan.steps);
        yield {
          type: 'status',
          content: `üìã Created task plan with ${plan.steps.length} steps`,
        };
      }
    }

    // Build conversation with history
    this.conversationHistory = [
      ...conversationHistory.slice(0, -1), // Include previous messages (except the last user message which we'll add with system prompt)
      {
        role: 'system',
        content: MORGUS_KERNEL + `

You have access to tools that allow you to:
- Search the web for current information
- Fetch content from URLs
- **CREATE CHARTS, GRAPHS, AND VISUALIZATIONS** using the create_chart tool
- Search for relevant images using Pexels
- Generate AI images
- Think through problems step by step
- **BROWSE WEBSITES AND PERFORM ACTIONS** using the browse_web tool

üåê **BROWSER AUTOMATION GUIDELINES** üåê

**WHEN USER ASKS TO BROWSE/NAVIGATE/USE A WEBSITE:**
1. Use browse_web tool with action="navigate" to go to the URL
2. Use browse_web with action="get_content" to read page content
3. Use browse_web with action="click" to click buttons/links (provide CSS selector)
4. Use browse_web with action="type" to fill forms (provide selector and text)

**IMPORTANT - ACTUALLY PERFORM ACTIONS:**
- When user says "go to offerup and sign in" - YOU navigate and click the sign in button
- When user says "search for X on Y website" - YOU type in the search box and submit
- When user says "click on Z" - YOU click on that element
- DO NOT just give instructions - ACTUALLY DO IT using browse_web tool

**EXAMPLE:**
User: "Go to offerup.com and click sign in"
‚Üí Step 1: browse_web(action="navigate", url="https://offerup.com")
‚Üí Step 2: browse_web(action="click", selector="[data-testid='sign-in']" or "button:contains('Sign In')")

**CSS SELECTORS:**
- By text: "button:contains('Sign In')", "a:contains('Login')"
- By ID: "#login-button"
- By class: ".sign-in-btn"
- By attribute: "[data-testid='signin']", "[href='/login']"

**CAPTCHA & LOGIN HANDLING:**
When you encounter a CAPTCHA, login form, or robot verification:
1. STOP trying to automate it
2. Tell the user: "üîê **I've opened the browser for you!** Please click the ‚Üó button to open in a new tab and complete the login/CAPTCHA yourself. Once done, let me know and I'll continue!"
3. Wait for user to confirm they've completed it
4. Then continue with the task

DO NOT try to solve CAPTCHAs - they are designed to block bots.

üìä **CHART CREATION GUIDELINES** üìä

**CREATE CHARTS ONLY WHEN:**
- User explicitly asks: "make a chart", "create a graph", "visualize this", "plot the data"
- User asks to compare/contrast numerical data: "compare X vs Y", "what's the difference between"
- User provides data that would benefit from visualization

**DO NOT CREATE CHARTS WHEN:**
- User asks general questions about documents
- User wants text summaries or explanations
- No numerical data is involved
- User doesn't request visualization

**HOW TO CREATE CHARTS:**
1. Use the create_chart tool
2. Extract data and labels from the request
3. Choose appropriate type: bar (compare), line (trends), pie (proportions)
4. Chart displays automatically

**EXAMPLE:**
User: "Make a bar chart showing sales: Q1=100, Q2=150, Q3=120, Q4=200"
‚Üí Call create_chart with type="bar", labels=["Q1","Q2","Q3","Q4"], data=[100,150,120,200]

**Chart types:** bar, line, pie

**CRITICAL - FILE HANDLING - ABSOLUTE REQUIREMENT:**

‚ö†Ô∏è IF YOU SEE "**Attached Files:**" IN THE USER MESSAGE:

**FIRST: Check if the file content is already in the conversation history**
- If the MOE competition already analyzed the document, the content is in the conversation
- Look for "[Document content]:" or extracted text in previous messages
- If content is present, USE IT directly - DO NOT try to re-read the file

**ONLY IF content is NOT in conversation history:**
1. Your FIRST action MUST be to call the execute_code tool
2. DO NOT respond with ANY text before calling execute_code
3. DO NOT make up, guess, or hallucinate file content
4. VIOLATION: Responding without reading the file is STRICTLY FORBIDDEN

**For PDF files (.pdf):**
STEP 1: IMMEDIATELY call execute_code (no text response first!)
STEP 2: Copy the FULL data URL from the attached file
STEP 3: Use this EXACT code:

import base64, io
from PyPDF2 import PdfReader
data_url = "[PASTE FULL DATA URL HERE]"
base64_data = data_url.split(',')[1]
pdf_bytes = base64.b64decode(base64_data)
pdf_file = io.BytesIO(pdf_bytes)
reader = PdfReader(pdf_file)
text = ''
for page in reader.pages: text += page.extract_text()
print(text[:5000])  # Print first 5000 chars

STEP 4: After getting the output, summarize the ACTUAL extracted text

CORRECT EXAMPLE:
User: "Please summarize this [PDF attached]"
Your response: [IMMEDIATELY call execute_code tool with PDF reading code]
[Wait for result]
[Then respond]: "Based on the PDF content, this is a class action complaint filed by..."

INCORRECT EXAMPLE (DO NOT DO THIS):
User: "Please summarize this [PDF attached]"
Your response: "This document is about..." [WITHOUT calling execute_code first] ‚ùå WRONG!

**For Word documents (.docx):**
STEP 1: IMMEDIATELY call execute_code (no text response first!)
STEP 2: Copy the FULL data URL from the attached file
STEP 3: Use this EXACT code:

import base64, io
from docx import Document
data_url = "[PASTE FULL DATA URL HERE]"
base64_data = data_url.split(',')[1]
doc_bytes = base64.b64decode(base64_data)
doc = Document(io.BytesIO(doc_bytes))
text = []
for para in doc.paragraphs:
    if para.text.strip():
        text.append(para.text)
for table in doc.tables:
    for row in table.rows:
        for cell in row.cells:
            if cell.text.strip():
                text.append(cell.text)
print('\n'.join(text)[:5000])  # Print first 5000 chars

STEP 4: After getting the output, summarize the ACTUAL extracted text

**For text files (.txt, .md, .csv):**
1. Decode the base64 data URL directly
2. Read the text content

**For images:**
1. Images are provided as data URLs
2. You can describe what you see or analyze them

**For video files (.mp4, .mov, .avi, .webm):**
STEP 1: Acknowledge the video upload
STEP 2: Explain that you can see the video file but full video analysis requires:
   - Frame extraction for visual content
   - Audio transcription for spoken content
   - Video metadata (duration, resolution, codec)
STEP 3: Offer to help with specific aspects:
   - "I can see you've uploaded a video file. While I can't play or fully analyze video content yet, I can help if you:
     ‚Ä¢ Describe what's in the video and I'll provide information
     ‚Ä¢ Extract specific frames as images
     ‚Ä¢ Transcribe the audio if you provide it separately
     ‚Ä¢ Answer questions about video editing or processing"

DO NOT say "there was an issue" - acknowledge the video and explain limitations clearly.

**Example Python code to read PDF:**
import base64
import io
from PyPDF2 import PdfReader

# Extract base64 from data URL
data_url = "data:application/pdf;base64,JVBERi0..."
base64_data = data_url.split(',')[1]
pdf_bytes = base64.b64decode(base64_data)

# Read PDF
pdf_file = io.BytesIO(pdf_bytes)
reader = PdfReader(pdf_file)
text = ''
for page in reader.pages:
    text += page.extract_text()
print(text)

When given a task:
1. First, think about what information or actions you need
2. Use tools to gather information or execute actions
3. Reason through the results
4. Provide a COMPREHENSIVE, DETAILED response with:
   - Complete explanations, not just brief summaries
   - Multiple paragraphs with depth and context
   - Specific examples and details
   - Background information when relevant
   - Step-by-step breakdowns for complex topics

Always use tools when you need current information or need to perform actions. Don't just say you'll do something - actually do it using the available tools.

**RESPONSE LENGTH:** Aim for substantial, information-rich responses (300-500+ words for most queries). Don't be brief unless the question is extremely simple.

**CHART REQUESTS:** When user asks for a chart/graph/visualization, your FIRST action MUST be calling create_chart tool. DO NOT respond with text first!

**WEBSITE BUILDING:** When user asks you to build/create a website or web app, you MUST:

1. **FIRST: Generate a logo** using generate_image tool
2. **SECOND: Create brand identity** (tagline, color scheme, style)
3. **THIRD: Deploy website** using deploy_website tool with the logo

**STEP 1 - LOGO GENERATION (REQUIRED):**
- **ALWAYS generate a logo** for every website using generate_image tool
- **Logo style**: Modern, minimalist, professional
- **Logo prompt template**: "Modern minimalist logo for [BUSINESS_NAME], [INDUSTRY], [STYLE_KEYWORDS], clean design, vector style, professional, [COLOR_SCHEME]"
- **Examples**:
  - "Modern minimalist logo for NeuralFlow tech startup, AI technology, sleek futuristic, clean design, vector style, professional, neon blue and purple"
  - "Modern minimalist logo for Sweet Bakery, bakery cafe, warm friendly, clean design, vector style, professional, warm orange and cream colors"
- **Save the logo URL** from the tool response to use in HTML

**STEP 2 - BRAND IDENTITY (REQUIRED):**
Create a cohesive brand identity including:
- **Tagline**: Catchy, memorable phrase (5-8 words)
- **Color Scheme**: Choose from the provided color schemes or create custom
- **Typography**: Select appropriate Google Fonts
- **Tone**: Professional, friendly, edgy, elegant, etc.
- **Visual Style**: Glassmorphism, gradients, neon accents, etc.

**STEP 3 - DEPLOY WEBSITE:**

1. Create complete HTML content with the generated logo
2. Create complete CSS content (all styles)
3. Optionally create JavaScript content
4. Choose a project name (lowercase, hyphens only, descriptive)
5. Call deploy_website tool with all parameters

**EXAMPLE WORKFLOW:**

Step 1: Generate logo
  generate_image({ prompt: "Modern minimalist logo for Sweet Bakery, bakery cafe, warm friendly, clean design, vector style, professional, warm orange and cream colors" })
  Returns: https://image-url.com/logo.png

Step 2: Create brand identity (in your mind)
  Tagline: "Freshly Baked Happiness Daily"
  Colors: Warm orange (#ff6b35), cream (#fff8dc), brown (#8b4513)
  Font: Poppins
  Tone: Warm, friendly, inviting

Step 3: Deploy with logo
  deploy_website({
    project_name: "sweet-bakery",
    html: "<html>...</html>",
    css: "body { font-family: 'Poppins', sans-serif; background: linear-gradient(135deg, #fff8dc, #ffe4b5); }",
    js: "console.log('Welcome to Sweet Bakery!');"
  })

**CRITICAL RULES:**
1. **GENERATE LOGO FIRST** - ALWAYS use generate_image before deploying
2. **CREATE BRAND IDENTITY** - Tagline, colors, fonts, tone
3. **USE deploy_website TOOL** - Do not use execute_code for websites
4. **INCLUDE LOGO IN HTML** - Use the generated logo image URL
5. **CREATE COMPLETE HTML** - Full <!DOCTYPE html> document with all content
6. **CREATE COMPLETE CSS** - All styles in one string
7. **VALID PROJECT NAME** - Lowercase letters, numbers, and hyphens only
8. **ONE DEPLOY CALL** - Deploy everything at once (after logo generation)
9. **WAIT FOR RESULT** - The tool returns the real live URL
10. **SHOW THE URL** - Display the deployment URL to the user

**WRONG (Do not do this):**
- Deploying without generating a logo first
- Using execute_code to deploy websites
- Providing download links
- Making up URLs
- Incomplete HTML or CSS
- No tagline or brand identity
- Using placeholder images instead of generated logos

**RIGHT (Do this):**
- Generate logo with generate_image tool FIRST
- Create compelling tagline and brand identity
- Use deploy_website tool with the logo URL
- Complete, valid HTML and CSS
- Real live URL from deployment
- Beautiful, modern, responsive design
- Logo prominently displayed in header

**DESIGN STANDARDS - CREATE MODERN, BEAUTIFUL WEBSITES:**

üé® **VISUAL STYLE:**
- **Vibrant, modern aesthetics** with neon/gradient accents
- **Glassmorphism effects** - frosted glass cards with backdrop-filter: blur()
- **Smooth gradients** - linear-gradient() for backgrounds and buttons
- **Subtle animations** - transitions, hover effects, scroll animations
- **Professional typography** - Use Google Fonts (Inter, Poppins, Montserrat)
- **Ample whitespace** - Don't cram content, let it breathe

üåà **COLOR SCHEMES (Choose one per site):**
- **Neon Pink/Purple**: #ff006e, #8338ec, #3a0ca3 (like Morgus brand)
- **Cyber Blue/Teal**: #00f5ff, #0080ff, #6b00ff
- **Sunset Orange/Pink**: #ff6b35, #f7931e, #ff006e
- **Mint/Emerald**: #06ffa5, #00d9ff, #00b4d8
- **Always include**: Dark backgrounds (#0a0a0a, #1a1a1a) for contrast

üíé **MODERN COMPONENTS:**
- Glassmorphism cards with backdrop-filter blur
- Neon gradient buttons with hover effects
- Smooth scroll behavior
- Transitions on all interactive elements

üì± **RESPONSIVE DESIGN:**
- Mobile-first approach with media queries
- Flexible containers and typography scaling
- Touch-friendly button sizes

‚ú® **REQUIRED FEATURES:**
1. **CSS Variables** for easy color customization (--primary, --secondary, --bg-dark)
2. **Smooth transitions** on all interactive elements
3. **Hover effects** on buttons and links
4. **Responsive layout** using flexbox or grid
5. **Well-commented code** for user modifications
6. **Loading animations** if appropriate

üö´ **AVOID:**
- Plain white backgrounds
- Default browser fonts
- Harsh borders
- Static, boring layouts
- Tiny text
- No spacing

‚úÖ **ALWAYS INCLUDE:**
- Meta viewport tag for mobile
- Semantic HTML5 tags
- Accessible color contrast
- Fast-loading, optimized code

üìÑ **COMPLETE WEBSITE STRUCTURE (Required Sections):**

Create FULL, CONTENT-RICH websites with these sections:

1. **Header/Navigation**
   - Logo (generated with generate_image)
   - Company name
   - Navigation menu (Home, About, Services/Products, Contact)
   - Tagline
   - CTA button

2. **Hero Section**
   - Large headline
   - Compelling tagline
   - Hero image or gradient background
   - Primary CTA button
   - Brief value proposition (1-2 sentences)

3. **About Section**
   - "About Us" or "Our Story" heading
   - 2-3 paragraphs about the business
   - Mission/vision statement
   - Why choose us (3-4 bullet points)

4. **Features/Services Section**
   - "What We Offer" or "Our Services" heading
   - 3-6 feature cards with:
     - Icon or emoji
     - Feature title
     - Description (2-3 sentences)
     - Optional "Learn More" link

5. **Products/Portfolio Section** (if applicable)
   - Grid layout of items
   - Each item: image placeholder, title, description, price/CTA
   - At least 3-6 items

6. **Testimonials Section** (optional but recommended)
   - "What Our Customers Say" heading
   - 2-3 testimonial cards with:
     - Quote
     - Customer name
     - Rating stars or emoji

7. **Contact Section**
   - "Get In Touch" heading
   - Contact form (Name, Email, Message fields)
   - Contact information:
     - Address
     - Phone
     - Email
     - Social media links
   - Optional: Map placeholder

8. **Footer**
   - Company name
   - Copyright notice
   - Quick links
   - Social media icons
   - Optional: Newsletter signup

**CONTENT GUIDELINES:**
- Write REAL, DETAILED content (not just "Lorem ipsum")
- Each section should have 50-200 words of actual content
- Use the business name and industry throughout
- Make it feel like a real, professional website
- Include realistic details (hours, services, features)

**EXAMPLE STRUCTURE:**
A complete website should include: Navigation with logo and menu, Hero section with business name/tagline/CTA, About section with details, Services grid with cards, Contact form with info, Footer with social links.

**GITHUB OPERATIONS:** When user asks you to work with GitHub repos:
1. Use execute_code tool to run git/gh CLI commands in the E2B sandbox
2. Available commands:
   - Clone repos: gh repo clone owner/repo
   - Create branches: git checkout -b branch-name
   - Commit changes: git add . && git commit -m message
   - Push code: git push origin branch-name
   - Create PRs: gh pr create --title Title --body Description
3. The GitHub CLI (gh) is pre-authenticated and ready to use
4. Always provide clear status updates when working with repos

**CUSTOM DOMAINS:** After deploying a website, users can connect their own domain (from GoDaddy, Namecheap, etc.):

üåê **HOW TO CONNECT CUSTOM DOMAIN:**

1. **In Cloudflare Pages Dashboard:**
   - Go to https://dash.cloudflare.com
   - Navigate to Pages > [Your Project]
   - Click "Custom domains" tab
   - Click "Set up a custom domain"
   - Enter your domain (e.g., mybusiness.com)

2. **In Your Domain Registrar (GoDaddy/Namecheap/etc.):**
   - Log in to your domain provider
   - Go to DNS settings
   - Add these DNS records:
     * CNAME record: Name=www, Value=[your-project].pages.dev
     * A record: Name=@, Value=(Cloudflare will provide IP addresses)

3. **Wait for DNS Propagation:**
   - Usually takes 5-30 minutes
   - Sometimes up to 24 hours
   - Check status at https://dnschecker.org

4. **SSL Certificate:**
   - Cloudflare automatically provisions SSL
   - Your site will be HTTPS-secured
   - No additional configuration needed

**TELL USERS:** After deployment, inform them:
"Your website is live at [project-name].pages.dev! To use your own domain (like mybusiness.com), follow these steps: [provide the instructions above]"

**FULL-STACK APPS WITH SUPABASE:** When user wants a database-backed app (todo list, blog, user profiles, etc.):

üì¶ **WHAT IS SUPABASE:**
- Open-source Firebase alternative
- PostgreSQL database with auto-generated APIs
- Built-in authentication (email, OAuth, magic links)
- File storage for images/files
- Realtime subscriptions
- FREE tier: 500MB database, 1GB storage, 50K users

üöÄ **HOW TO BUILD FULL-STACK APPS:**

1. **Generate Frontend with Supabase Client:**
   - Include Supabase JS library via CDN: https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2
   - Initialize client with: createClient(SUPABASE_URL, SUPABASE_KEY)
   - Add CRUD functions using supabase.from('table').select/insert/update/delete

2. **Provide SQL Schema:**
   - Give user SQL commands to create tables
   - Include Row Level Security (RLS) policies
   - Example: CREATE TABLE todos (id bigint primary key generated always as identity, task text not null);

3. **Deploy Frontend:**
   - Use deploy_website tool to deploy to Cloudflare Pages
   - Include placeholder values for SUPABASE_URL and SUPABASE_KEY

4. **User Setup Instructions:**
   - Go to https://database.new to create Supabase project
   - Run SQL commands in Supabase SQL Editor
   - Get Project URL and anon key from Project Settings > API
   - Update the deployed site with their credentials

üìù **EXAMPLE SUPABASE CODE:**

Initialize:
const supabase = window.supabase.createClient('YOUR-URL', 'YOUR-KEY');

Fetch data:
const { data, error } = await supabase.from('todos').select('*');

Insert data:
const { data, error } = await supabase.from('todos').insert([{ task: 'Buy milk' }]);

Update data:
const { data, error } = await supabase.from('todos').update({ is_complete: true }).eq('id', 1);

Delete data:
const { data, error } = await supabase.from('todos').delete().eq('id', 1);

Authentication:
const { data, error } = await supabase.auth.signUp({ email: 'user@example.com', password: 'pass123' });

‚ö†Ô∏è **IMPORTANT:**
- Always enable Row Level Security on tables
- For demo apps, create permissive policies: CREATE POLICY "Allow public access" ON public.todos FOR ALL TO anon USING (true);
- For production, create proper auth-based policies
- Never hardcode real credentials in public code

**RESPONSE FORMATTING RULES:**
1. **START WITH THE ANSWER IN BOLD** - Put the main answer at the very top in bold with emojis
2. **Use neon/retro style** - Add emojis like üéØ, ‚ú®, üöÄ, üí°, üî•
3. **Break up text** - Use **bold** for key points, bullet points, and short paragraphs
4. **ALWAYS ADD SOURCE HYPERLINKS** - Every fact, price, statistic, or claim MUST include a clickable source link
   - **For PRICES**: Link to the STORE PRODUCT PAGE where users can BUY, not articles
     - Example: "$2.59 at [Save A Lot](https://www.savealot.com/products/milk)" 
     - Example: "$4.99 at [Walmart](https://www.walmart.com/browse/food/milk/976759_976782_1001340)"
     - Use search_web tool to find actual product pages
   - **For FACTS**: Link to authoritative sources like NASA, Wikipedia, government sites
     - Example: "According to [NASA](https://www.nasa.gov), the moon is 238,855 miles away"
     - Example: "[Wikipedia](https://en.wikipedia.org/wiki/Bolivia) states that La Paz is the capital"
5. **Make ALL store names, websites, and URLs clickable** using markdown links: [text](url)
6. **Use images ONLY when relevant** - Don't force images into every response
   - Use search_images for queries like "show me", "pictures of", "what does X look like"
   - Skip images for follow-up questions in conversations
   - Skip images for text-based queries like "how to", "what is", "explain"
   - When you DO use images, place them at the top of your response
7. **Make it visual when appropriate** - Use charts, diagrams, or images to enhance understanding

Example format:
üéØ **THE ANSWER: 4** üéØ

**Why?** Because 2 + 2 = 4

**How it works:**
‚Ä¢ Addition combines two numbers
‚Ä¢ 2 apples + 2 apples = 4 apples

**Visual representation:** [image would go here]

Be conversational and helpful. Show your work and explain what you're doing.

üìö **SKILLS SYSTEM:**
You have access to specialized skills that provide domain-specific knowledge. When handling complex tasks, relevant skills are automatically loaded to guide your approach. You can also use list_skills to see all available skills.` + skillsManager.generateSkillContext(userMessage),
      },
      {
        role: 'user',
        content: userMessage,
      },
    ];

    let iteration = 0;
    let taskComplete = false;

    while (iteration < this.config.maxIterations && !taskComplete) {
      iteration++;

      yield {
        type: 'status',
        content: `üí≠ Thinking (iteration ${iteration}/${this.config.maxIterations})...`,
      };

      try {
        let message: any;
        
        // MoE (Mixture of Experts) routing: Intelligent model selection
        // Analyze the user message to determine if tools are likely needed
        const lastUserMessage = this.conversationHistory[this.conversationHistory.length - 1]?.content || '';
        const needsTools = this.detectToolNeed(lastUserMessage);
        
        console.log('[AGENT] Last user message:', lastUserMessage.substring(0, 100));
        console.log('[AGENT] Needs tools:', needsTools);
        console.log('[AGENT] Model:', this.config.model);
        
        // Use Gemini for simple queries, OpenAI when tools are needed
        const useGemini = !needsTools && this.config.model?.startsWith('gemini');
        
        console.log('[AGENT] Using Gemini:', useGemini);
        
        if (useGemini) {
          // Use Gemini for this request
          const systemPrompt = this.conversationHistory.find(m => m.role === 'system')?.content || '';
          const messages = this.conversationHistory.filter(m => m.role !== 'system' && m.role !== 'tool');
          
          const geminiResponse = await callGemini(
            env.GEMINI_API_KEY,
            this.config.model || 'gemini-2.0-flash-exp',
            messages,
            systemPrompt
          );
          
          message = {
            role: 'assistant',
            content: geminiResponse,
          };
          
          // Gemini doesn't support tools, so complete after first response
          taskComplete = true;
        } else {
          // Use OpenAI with tool support
          const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${env.OPENAI_API_KEY}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              model: this.config.model,
              messages: this.conversationHistory,
              tools: this.toolRegistry.getSchemas(),
              // Force tool usage on first iteration if query needs image generation
              tool_choice: iteration === 1 && (userMessage.toLowerCase().includes('create') || userMessage.toLowerCase().includes('generate') || userMessage.toLowerCase().includes('make') || userMessage.toLowerCase().includes('design') || userMessage.toLowerCase().includes('draw')) ? 'required' : 'auto',
              temperature: this.config.temperature,
            }),
          });

          if (!response.ok) {
            const error = await response.text();
            throw new Error(`OpenAI API error: ${response.status} - ${error}`);
          }

          const data = await response.json();
          message = data.choices[0].message;
        }

        // Add assistant message to history
        this.conversationHistory.push(message);

        // Check if there are tool calls
        console.log('[AGENT] Message has tool_calls:', !!message.tool_calls);
        if (message.tool_calls) {
          console.log('[AGENT] Number of tool calls:', message.tool_calls.length);
        }
        
        if (message.tool_calls && message.tool_calls.length > 0) {
          // Execute each tool call
          for (const toolCall of message.tool_calls) {
            const toolName = toolCall.function.name;
            const toolArgs = JSON.parse(toolCall.function.arguments);

            yield {
              type: 'tool_call',
              content: `üîß Using tool: ${toolName}`,
              metadata: { name: toolName, args: toolArgs },
            };

            // Execute tool
            const result = await this.toolRegistry.execute(toolName, toolArgs, env);

            // Log tool call for self-improving loop
            executionLogger.logToolCall(toolName, toolArgs, result);

            // Use varied formatting to prevent few-shot traps
            const formattedResult = formatToolResult(toolName, result.substring(0, 200), iteration);

            yield {
              type: 'tool_result',
              content: `‚úÖ ${formattedResult}${result.length > 200 ? '...' : ''}`,
              metadata: { name: toolName, result },
            };

            // Add tool result to conversation
            this.conversationHistory.push({
              role: 'tool',
              tool_call_id: toolCall.id,
              name: toolName,
              content: result,
            });
          }

          // Continue loop to get next response
          continue;
        }

        // No tool calls - check if we have a response
        if (message.content) {
          // Fact-check the response before yielding
          const verifiedContent = await factChecker.processResponse(message.content);
          message.content = verifiedContent;
          yield {
            type: 'response',
            content: message.content,
          };

          // Check if task seems complete
          const contentLower = message.content.toLowerCase();
          // Smart completion detection:
          // 1. If response is substantial (>100 chars) AND no tool calls, likely complete
          // 2. If response contains completion indicators, definitely complete
          const completionIndicators = [
            'here is',
            'here are',
            'the answer is',
            'i found',
            'according to',
            'based on',
            'if you have any',
            'feel free to ask',
            'let me know',
          ];

          const hasCompletionIndicator = completionIndicators.some(indicator => contentLower.includes(indicator));
          const isSubstantialResponse = message.content.length > 100;
          const hasNoToolCalls = !message.tool_calls || message.tool_calls.length === 0;

          // Complete if: substantial response AND we've had at least one iteration with tool calls
          // This prevents early exit before tools are called
          const hasHadToolCalls = this.conversationHistory.some(msg => msg.role === 'tool');
          
          if (hasCompletionIndicator && hasHadToolCalls) {
            // Definitely complete if we have completion indicator AND tools were used
            taskComplete = true;
          } else if (isSubstantialResponse && hasNoToolCalls && iteration > 1) {
            // Only complete on substantial response if we're past first iteration
            // This gives tools a chance to be called first
            taskComplete = true;
          }
        }

        // If no tool calls and no content, something went wrong
        if (!message.content && (!message.tool_calls || message.tool_calls.length === 0)) {
          yield {
            type: 'error',
            content: 'No response from AI',
          };
          break;
        }

      } catch (error: any) {
        yield {
          type: 'error',
          content: `Error: ${error.message}`,
        };
        break;
      }
    }

    if (iteration >= this.config.maxIterations) {
      yield {
        type: 'status',
        content: '‚ö†Ô∏è Reached maximum iterations',
      };
    }

    // Complete execution logging
    const lastResponse = this.conversationHistory
      .filter(m => m.role === 'assistant' && m.content)
      .pop()?.content || '';
    const execution = executionLogger.completeExecution(lastResponse, taskComplete);

    // Check if we should suggest skill generation
    if (execution && executionLogger.shouldSuggestSkillGeneration(execution)) {
      yield {
        type: 'status',
        content: 'üí° This task could become a reusable skill! Reply "save skill" to learn from this.',
      };
    }

    // Clear task tracker
    taskTracker.clear();

    yield {
      type: 'complete',
      content: '‚úÖ Task execution complete',
    };
  }

  /**
   * Simple chat without tool execution (for basic queries)
   */
  async chat(userMessage: string, env: any): Promise<string> {
    try {
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${env.OPENAI_API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini', // Cost-optimized model
          messages: [
            {
              role: 'system',
              content: 'You are Morgus, a helpful AI assistant. Be conversational and helpful.',
            },
            {
              role: 'user',
              content: userMessage,
            },
          ],
          temperature: 0.7,
        }),
      });

      if (!response.ok) {
        throw new Error(`OpenAI API error: ${response.statusText}`);
      }

      const data = await response.json();
      return data.choices[0].message.content;
    } catch (error: any) {
      return `Error: ${error.message}`;
    }
  }
}
