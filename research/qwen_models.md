# Qwen Free Models on OpenRouter

## Available Models

1. **Qwen3 Coder 480B A35B (free)**
   - ID: `qwen/qwen3-coder-480b-a35b:free`
   - 4.64B tokens
   - 262K context
   - Mixture-of-Experts (MoE) code generation model
   - Optimized for agentic coding tasks: function calling, tool use

2. **Qwen3 4B (free)**
   - ID: `qwen/qwen3-4b:free`
   - 131M tokens
   - 41K context
   - 4 billion parameter dense language model
   - Supports both general-purpose and reasoning-intensive tasks
   - Introduces a dual-mode architecture

3. **Qwen2.5-VL 7B Instruct (free)**
   - ID: `qwen/qwen2.5-vl-7b-instruct:free`
   - 91.7M tokens
   - 33K context
   - Multimodal LLM (vision + language)
   - SoTA on visual understanding benchmarks

## Recommendation
For MOE replacement of DeepSeek, use **Qwen3 4B** - it's fast, general-purpose, and has good reasoning capabilities.
